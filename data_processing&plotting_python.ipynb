{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of Python in Groundwater Hydrology\n",
    "# Session 2 - Data processing and plotting\n",
    "\n",
    "The objective of this notebook is to demonstrate the incredible power of the Pandas library for processing time series data. We will also see how to create graphs in Matplotlib. For this exercise we will make use of online data that can be directly accessed from within Python.\n",
    "\n",
    "First we import some libraries, including the Python core library `requests`, which can be used to get online files and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some climate data available from the database of the Royal Dutch Meteorological Institute (KNMI). The data are made available through a so-called application programming interface (API). Details can be found <A href=\"https://www.knmi.nl/kennis-en-datacentrum/achtergrond/data-ophalen-vanuit-een-script\">here</A>, but unfortunately the information is only in Dutch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime('19010101') \n",
    "current_date = pd.to_datetime('today') # Today\n",
    "\n",
    "url = 'https://www.daggegevens.knmi.nl/klimatologie/daggegevens'\n",
    "\n",
    "params = {\n",
    "    'start': start_date.strftime('%Y%m%d'),\n",
    "    'end': current_date.strftime('%Y%m%d'),\n",
    "    'inseason': str(int(False)),\n",
    "    'vars': \":\".join(['TG', 'TX', 'RH']),\n",
    "    'stns': '260', # De Bilt\n",
    "    'fmt': 'json',\n",
    "}\n",
    "\n",
    "# Send the API request\n",
    "response = requests.get(url, params=params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The requested file format was a json file, which can be converted to a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(response.json())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do some manipulation of the DataFrame: We use the 'date' column for the index, we drop the station code (we only obtained data from a single station, so there is no real need to keep it) and we divide the temperatures by ten, because they are reported in tenths of degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.index = pd.to_datetime(df['date'])\n",
    "df = df.drop(['station_code'], axis=1)\n",
    "\n",
    "df['TG'] = df['TG'] / 10. # Mean daily temperature\n",
    "df['TX'] = df['TX'] / 10. # Daily maximum temperature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The daily precipitation sums are stored in the column labelled 'RH'. The next code cell calculates the maximum number of consecutive days in a year without any significant precipitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for -1 values, these represent days with <0.5 mm of precipitation and set to zero.\n",
    "idx = df['RH'] == -1\n",
    "df.loc[idx, 'RH'] = 0\n",
    "\n",
    "# Select only the rows with precipitation larger than zero\n",
    "idx = df['RH'] > 0\n",
    "dfr = df.loc[idx, 'RH'].copy()\n",
    "\n",
    "# Calculate the number of days between the dates in dfr\n",
    "dfd = dfr.index.to_series().diff().dt.days\n",
    "\n",
    "# Calculate the maximum number of days per year\n",
    "dfy = dfd.resample('1Y').max()\n",
    "\n",
    "# Set the index to the year only\n",
    "dfy.index = dfy.index.year\n",
    "dfy.plot.bar(figsize=(12, 8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code cell calculates the deviation of the mean annual temperature from the 1961 - 1990 average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the values for the years 1961 - 1990\n",
    "idx = (df.index.year >= 1961) & (df.index.year <= 1990)\n",
    "# Store the daily temperatures in a separate Series and calculate the mean\n",
    "dfsub = df.loc[idx, 'TG']\n",
    "tmean = dfsub.mean()\n",
    "print(tmean)\n",
    "\n",
    "# Get the yearly averages and subtract the mean\n",
    "dfy = df['TG'].resample('1Y').mean()\n",
    "dT = dfy - tmean\n",
    "\n",
    "# Plot the deviation from the mean\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(dfy.index, dT);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be a warming trend since the 1960. Let's also plot the atmospheric CO$_2$ levels measured at the Mauna Loa station. The data are available online as a csv file, which can be read directly by Pandas without the need to download it first. Some tweaking of the `read_csv` arguments is needed to import the data in the right way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfco2 = pd.read_csv(\"https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt\", \n",
    "    skiprows=58,\n",
    "    # delimiter=' ',\n",
    "    delim_whitespace=True,\n",
    "    header=None,\n",
    "    names=['year', 'month', 'dec_date', 'monthly_average', 'de-seasonalized', 'days', 'std_days', 'unc_mon_mean'],\n",
    "    parse_dates=[['year','month']],  \n",
    "    index_col=\"year_month\",\n",
    ")\n",
    "\n",
    "# Plot the data alongside the De Bilt temperature trend\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(dfy.index, dT)\n",
    "axco2 = ax.twinx()\n",
    "axco2.plot(dfco2.index, dfco2['monthly_average'], 'C2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature data can also be plotted as 'warming stripes', which you may have seen before. See <A href=\"https://www.climate-lab-book.ac.uk/2018/warming-stripes/\">https://www.climate-lab-book.ac.uk/2018/warming-stripes/</A>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the vaues\n",
    "dTmin = dT.min()\n",
    "dTmax = dT.max()\n",
    "dTscaled = (dT - dTmin) / (dTmax - dTmin)\n",
    "\n",
    "# Get the colors from the bwr colormap\n",
    "from matplotlib import cm\n",
    "colors =  [cm.bwr(dTs) for dTs in dTscaled]\n",
    "\n",
    "# Create a bar plot, with each bar being of equal height but with a different colour\n",
    "fig, ax = plt.subplots(figsize=(8, 1))\n",
    "ax.bar(dfy.index, np.ones(len(dT)), width=365, color=colors)\n",
    "ax.axis('off')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's create a plot of the number of days since the first of January on which a certain temperature was reached. We'll create three graphs, each for a specific temperature (10, 20 and 30 degrees). A `for` loop repeats the code that calculates the number of days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with three graphs\n",
    "fig, axs = plt.subplots(nrows=3, figsize=(8, 9))\n",
    "\n",
    "# Repeat for temperatures 10, 20 and 30 degrees.\n",
    "for i, T in enumerate([10, 20, 30]):\n",
    "    # Select the days with a temperature higher than T\n",
    "    idx = df['TX'] > T\n",
    "    dfm = df.loc[idx, 'TX'].to_frame()\n",
    "    # Calculate the number of days since the first of January\n",
    "    dfm['doy'] = dfm.index.dayofyear\n",
    "    # Find the minimum of doy for each year\n",
    "    dfy = dfm['doy'].resample('1Y').min()\n",
    "\n",
    "    # Plot a bar graph\n",
    "    ax = axs[i]\n",
    "    ax.bar(dfy.index, dfy, width=365)\n",
    "    ax.set_ylabel(f\"Days to reach {T} \\u2103\")\n",
    "\n",
    "# Set some properties of the graph to improve their appearance\n",
    "for ax in axs:\n",
    "    ax.grid(ls=':')\n",
    "    if ax != axs[-1]:\n",
    "        ax.set_xticklabels([])\n",
    "    else:\n",
    "        ax.set_xlabel('Year')\n",
    "\n",
    "# Let Matplotlib optimize the use of space\n",
    "plt.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Bonus material***: Creating a kmz file with hydrographs\n",
    "\n",
    "This final code cell is a demonstration of how data from an Excel file can be read, plotted and saved to separate graphs (png format). It is even possible to store link these figures to the well coordinates in a kmz file, which can be opened in Google Earth. For this you'll need the simplekml library, which can be installed with\n",
    " \n",
    " pip install simplekml\n",
    "\n",
    " or (when using conda)\n",
    "\n",
    " conda install -c conda-forge simplekml\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplekml\n",
    "from pathlib import Path\n",
    "kmlfile = simplekml.Kml()\n",
    "\n",
    "# Create hydrographs subfolder (for output) if it does not yet exist\n",
    "Path('hydrographs/').mkdir(exist_ok=True)\n",
    "\n",
    "xldata = pd.read_excel(\n",
    "    'ameland_exercise.xlsx', \n",
    "    sheet_name=None, \n",
    "    index_col=0, \n",
    "    parse_dates=True,\n",
    ")\n",
    "xydata = pd.read_excel(\n",
    "    'ameland_exercise.xlsx', \n",
    "    sheet_name=\"coordinates\",\n",
    ")\n",
    "\n",
    "def plot_df(df):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(df.index, df[\"head (cm amsl)\"])\n",
    "    ax.set_ylabel('h (cm)')\n",
    "    ax.set_title(sheet)\n",
    "    fname = f\"hydrographs/{sheet}.png\"\n",
    "    plt.savefig(fname)\n",
    "    \n",
    "    return fname\n",
    "\n",
    "for i, sheet in enumerate(xldata):\n",
    "    if (i == 0):\n",
    "        continue\n",
    "    \n",
    "    well_id = sheet[:-3]\n",
    "    idx = xydata['well_id'] == well_id\n",
    "    x = xydata['long'].loc[idx].values[0]\n",
    "    y = xydata['lat'].loc[idx].values[0]\n",
    "\n",
    "    fname = plot_df(xldata[sheet])\n",
    "\n",
    "    path = kmlfile.addfile(fname)\n",
    "    point = kmlfile.newpoint(name=well_id, coords=[[str(x), str(y)]])\n",
    "    point.description = '<img src=\"' + path +'\" alt={well_id} width=\"400\" height=\"300\" align=\"left\" />'\n",
    "    \n",
    "kmlfile.savekmz('hydrographs/ameland.kmz', format=False) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was presented by Vincent Post on 22 June 2023 as part of the two-session webinar series titled \"Use of Python in Groundwater Hydrology\", organised by the International Association of Hydrogeologists (IAH) Lebanon Chapter in collaboration with the Department of Geology at the American University of Beirut."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopandas_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
